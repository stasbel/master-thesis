\documentclass{spbau-diploma}

\newcommand\TODO[1]{\textcolor{red}{TODO: #1}}  % To mark TODOs.
\overfullrule=3mm  % To note hbox errors.
\newcommand\sep{\newline\textcolor{red}{\rule{\textwidth}{3pt}}\newline\indent}  % RU-EN separator

% Chars count
\usepackage{shellesc}
\usepackage{lastpage}
\newread\tmp
\newcommand{\stats}[1]{
\ShellEscape{texcount -1 -sum=1,1,1,1,1,1,1 -merge -char -q #1.tex output.bbl > #1-chars.sum}
\openin\tmp=#1-chars.sum%
\read\tmp to \chars%
\closein\tmp%
\ShellEscape{texcount -1 -sum=1,1,1,1,1,1,1 -merge -q #1.tex output.bbl > #1-words.sum}
\openin\tmp=#1-words.sum%
\read\tmp to \words%
\closein\tmp%
\noindent\textcolor{red}{\Huge Chars: \the\numexpr \words + \chars \relax \slash 40000}\\
\textcolor{red}{\Huge Pages: \pageref*{LastPage}\slash 40}
}

% В рамках данной работы предлагается TalkNet: сверточная неавторегрессионная нейронная модель, которая решает задачу синтеза речи. Модель состоит из двух прямых (feed-forward) полностью сверточных нейронных сетей. Первая сеть служит для предсказания длительности входных символов (графем), выравнивая таким образом входную последовательность на длину мэл-спектрограммы. Далее, производится операция расширения (expansion) входного текста путем повторения каждого символа в соответствии с предсказанной длительностью. Вторая сеть генерирует мэл-спектрограмму из развернутого текста. Операция разворачивания, таким образом, позволяет построить неавторегрессионную архитектуру. Эксперименты с набором данных LJSpeech показывают, что качество речи TalkNet сравнимо с авторегрессионными подходами. Модель очень компактна -- она имеет всего около 10.8 миллионов обучаемых параметров, что почти в 3 раза меньше, чем предлагают современные модели преобразования текста в речь. Неавторегрессионная архитектура также позволяет быстро обучаться и делать выводы.
% This work propose TalkNet, a convolutional non-autoregressive neural model for speech synthesis. The model consists of two feed-forward convolutional networks. The first network predicts grapheme durations. An input text is expanded by repeating each symbol according to the predicted duration. The second network generates a mel-spectrogram from the expanded text. To train a grapheme duration predictor, the grapheme duration of the training dataset extracted using a pre-trained Connectionist Temporal Classification (CTC)-based speech recognition model. The explicit duration prediction eliminates word skipping and repeating. Experiments on the LJSpeech dataset show that the speech quality nearly matches auto-regressive models. The model is very compact -- it has 10.8M parameters, almost 3x less than the present state-of-the-art text-to-speech models. The non-autoregressive architecture allows for fast training and inference.

\begin{document}

% \stats{main}

\include{parts/begining}

\include{parts/ru/introduction}  % *
\include{parts/ru/related-work}  % 1
\include{parts/ru/model}  % 2
\include{parts/ru/training}  % 3
\include{parts/ru/results}  % 4
\include{parts/ru/conclusion}  % *

\include{parts/ending}

\end{document}
